{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of cities in the dataset\n",
    "cities = [\"austin\", \"chicago\", \"kitsap\", \"tyrol-w\", \"vienna\"]\n",
    "\n",
    "# Path to the images\n",
    "path = \"/home/wgt/Desktop/train/images/\"\n",
    "\n",
    "for city in cities:\n",
    "    for i in range(1, 37):  # Assuming there are 36 images per city\n",
    "        dim = (256, 256)  # (w,h)\n",
    "        image_path = f\"{path}{city}{i}.tif\"\n",
    "        image = cv2.imread(image_path, 0)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue  # Skip this iteration and go to the next image\n",
    "        resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "        (thresh, im_bw) = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY)\n",
    "        # Adjust the output path as needed\n",
    "        cv2.imwrite(f'/home/wgt/Desktop/train/mask_train/{city}{i}.png', im_bw)\n",
    "\n",
    "path = \"masks_train1/\"\n",
    "\n",
    "# for i in range(1,2088):\n",
    "#     dim = (256, 256) #(w,h)\n",
    "#     image = cv2.imread(path + str(i) + \".png\", 0)\n",
    "#     resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "#     (thresh, im_bw) = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY)\n",
    "#     cv2.imwrite('mask_train/' + str(i) + '.png', im_bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n",
      "(4, 5000, 5000, 3) (4, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def generate_batches(batch_size, cities, image_path_base, mask_path_base):\n",
    "    batch_images = []\n",
    "    batch_masks = []\n",
    "    for city in cities:\n",
    "        for i in range(1, 37):  # Assuming there are 36 images per city\n",
    "            image_path = f\"{image_path_base}{city}{i}.tif\"\n",
    "            mask_path = f\"{mask_path_base}{city}{i}.png\"\n",
    "            \n",
    "            # Load the image and convert to a numpy array\n",
    "            img = Image.open(image_path)\n",
    "            arr = np.array(img)\n",
    "            batch_images.append(arr)\n",
    "            \n",
    "            # Load the mask, convert to a numpy array, and expand its dimensions\n",
    "            mask = Image.open(mask_path)\n",
    "            mask_arr = np.array(mask)\n",
    "            mask_arr = np.expand_dims(mask_arr, -1)  # Add a new axis\n",
    "            batch_masks.append(mask_arr)\n",
    "            \n",
    "            # Yield a batch when the specified batch size is reached\n",
    "            if len(batch_images) == batch_size:\n",
    "                yield np.array(batch_images), np.array(batch_masks)\n",
    "                batch_images = []  # Reset for the next batch\n",
    "                batch_masks = []\n",
    "    \n",
    "    # Yield any remaining images and masks as the last batch\n",
    "    if batch_images:\n",
    "        yield np.array(batch_images), np.array(batch_masks)\n",
    "\n",
    "# Example usage\n",
    "cities = [\"austin\", \"chicago\", \"kitsap\", \"tyrol-w\", \"vienna\"]\n",
    "image_path_base = \"/home/wgt/Desktop/train/images/\"\n",
    "mask_path_base = \"/home/wgt/Desktop/train/mask_train/\"\n",
    "\n",
    "batch_size = 4  # Adjust based on your memory constraints\n",
    "\n",
    "for images, masks in generate_batches(batch_size, cities, image_path_base, mask_path_base):\n",
    "    # Process your batches here\n",
    "    # For example, train your model\n",
    "    print(images.shape, masks.shape)  # Just to demonstrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "# cities = [\"austin\", \"chicago\", \"kitsap\", \"tyrol-w\", \"vienna\"]\n",
    "# images = []\n",
    "# masks = []\n",
    "\n",
    "# # Adjust these paths as needed\n",
    "# image_path_base = \"/home/wgt/Desktop/train/images/\"\n",
    "# mask_path_base = \"/home/wgt/Desktop/train/mask_train/\"\n",
    "\n",
    "# for city in cities:\n",
    "#     for i in range(1, 37):  # Assuming there are 36 images per city\n",
    "#         # Construct the path for the current image and mask\n",
    "#         image_path = f\"{image_path_base}{city}{i}.tif\"\n",
    "#         mask_path = f\"{mask_path_base}{city}{i}.png\"\n",
    "        \n",
    "#         # Open and convert the image to a numpy array\n",
    "#         img = Image.open(image_path)\n",
    "#         arr = np.array(img)\n",
    "#         images.append(arr)\n",
    "        \n",
    "#         # Open and convert the mask to a numpy array, then expand its dimensions\n",
    "#         img = Image.open(mask_path)\n",
    "#         arr = np.array(img)\n",
    "#         arr = np.expand_dims(arr, -1)  # Add a new axis to fit model requirements\n",
    "#         masks.append(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256, 256, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_hdf5(batch_generator, hdf5_path, total_images, image_shape, mask_shape):\n",
    "    with h5py.File(hdf5_path, 'w') as hdf:\n",
    "        # Assuming image_shape and mask_shape correctly reflect your data\n",
    "        images_dset = hdf.create_dataset('images', shape=(total_images, *image_shape), dtype=np.uint8, compression='gzip', compression_opts=9)\n",
    "        masks_dset = hdf.create_dataset('masks', shape=(total_images, *mask_shape), dtype=np.uint8, compression='gzip', compression_opts=9)\n",
    "\n",
    "        start_idx = 0\n",
    "        for images_batch, masks_batch in batch_generator:\n",
    "            end_idx = start_idx + images_batch.shape[0]\n",
    "            images_dset[start_idx:end_idx, :, :, :] = images_batch  # Ensure correct slicing\n",
    "            masks_dset[start_idx:end_idx, :, :, :] = masks_batch\n",
    "            start_idx = end_idx\n",
    "\n",
    "# Adjust these to match the correct dimensions of your images and masks\n",
    "image_shape = (5000, 5000, 3)  # Update this based on your actual image dimensions\n",
    "mask_shape = (5000, 5000, 1)  # Update this for your actual mask dimensions\n",
    "\n",
    "# Ensure the batch generator is producing the correct shape; otherwise, adjust it accordingly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
